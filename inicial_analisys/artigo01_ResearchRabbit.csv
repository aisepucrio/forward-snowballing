DOI,PMID,arXiv ID,Title,Abstract,Authors,Journal,Year
10.1109/tse.2021.3116768,,,Transfer Learning Across Variants and Versions : The Case of Linux Kernel Size,"With large scale and complex configurable systems, it is hardfor users to choose the right combination of options (i.e., configurations)in order to obtain the wanted trade-off between functionality and per-formance goals such as speed or size. Machine learning can help inrelating these goals to the configurable system options, and thus, predictthe effect of options on the outcome, typically after a costly training step.However, many configurable systems evolve at such a rapid pace that itis impractical to retrain a new model from scratch for each new version.In this paper, we propose a new method to enable transfer learningof binary size predictions among versions of the same configurablesystem. Taking the extreme case of the Linux kernel with its14,500configuration options, we first investigate how binary size predictionsof kernel size degrade over successive versions. We show that thedirect reuse of an accurate prediction model from 2017 quickly becomesinaccurate when Linux evolves, up to a 32% mean error by August 2020.We thus propose a new approach for transfer evolution-aware modelshifting (TEAMS). It leverages the structure of a configurable systemto transfer an initial predictive model towards its future versions witha minimal amount of extra processing for each version. We show thatTEAMS vastly outperforms state of the art approaches over the 3 yearshistory of Linux kernels, from 4.13 to 5.8.","Hugo Martin,Hugo Martin,Mathieu Acher,Mathieu Acher,Luc Lesoil,Luc Lesoil,Jean Marc Jézéquel,Jean-Marc Jézéquel,Djamel Eddine Khelladi,Djamel Eddine Khelladi,Juliana Alves Pereira,Juliana Alves Pereira,Juliana Alves Pereira",IEEE Transactions on Software Engineering,2021.0
10.1109/tsc.2022.3142853,,,FOCloud: Feature Model Guided Performance Prediction and Explanation for Deployment Configurable Cloud Applications,"The increasing heterogeneity of the VM offerings on public IaaS clouds} gives rise to a very large number of deployment options for constructing distributed, multi-component cloud applications. However, selecting an appropriate deployment variant, i.e., a valid combination of deployment options, to meet required performance levels is non-trivial. The combinatorial explosion of the deployment space makes it infeasible to measure the performance of all deployment variants to build a comprehensive empirical performance model. To address this problem, we propose Feature-Oriented Cloud (FOCloud), a performance engineering approach for deployment configurable cloud applications. FOCloud (i) uses feature modeling to structure and constrain the valid deployment space by modeling the commonalities and variations in the different deployment options and their inter-dependencies, (ii) uses sampling and machine learning to incrementally and cost-effectively build a performance prediction model whose input variables are the deployment options, and the output variable is the performance of the resulting deployment variant, and (iii) uses Explainable AI techniques to provide explanations for the prediction outcomes of valid deployment variants in terms of the deployment options We demonstrate the practicality and feasibility of FOCloud by applying it to an extension of the RuBiS benchmark application deployed on Google Cloud.","Indika Priyantha Kumara,Indika Kumara,Mohamed Ariz,Mohamed Hameez Ariz,Mohan Baruwal Chhetri,Mohan Baruwal Chhetri,Majeed Mohammadi,Majeed Mohammadi,Willem-Jan Van Den Heuvel,Willem‐Jan van den Heuvel,Damian Andrew Andrew Tamburri,Damian A. Tamburri",IEEE Transactions on Services Computing,2022.0
10.1109/tse.2022.3171404,,,Were Not Gonna Break It! Consistency-Preserving Operators for Efficient Product Line Configuration,"When configuring a software product line, finding a good trade-off between multiple orthogonal quality concerns is a challenging multi-objective optimisation problem. State-of-the-art solutions based on search-based techniques create invalid configurations in intermediate steps, requiring additional repair actions that reduce the efficiency of the search. In this work, we introduce <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">consistency-preserving configuration operators</i> (CPCOs)—genetic operators that maintain valid configurations throughout the entire search. CPCOs bundle coherent sets of changes: the activation or deactivation of a particular feature together with other (de)activations that are needed to preserve validity. In our evaluation, our instantiation of the IBEA algorithm with CPCOs outperforms two state-of-the-art tools for optimal product line configuration in terms of both speed and solution quality. The improvements are especially pronounced in large product lines with thousands of features.","José-Miguel Horcas,Jose Miguel Horcas,Daniel Strüber,Daniel Struber,Alexandru Burdusel,Alexandru Burdusel,Jabier Martínez,Jabier P. Martinez,Steffen Zschaler,Steffen Zschaler",IEEE Transactions on Software Engineering,2022.0
10.1145/3510455.3512792,,,Towards Incremental Build of Software Configurations,"Building software is a crucial task to compile, test, and deploy software systems while continuously ensuring quality. As software is more and more configurable, building multiple configurations is a pressing need, yet, costly and challenging to instrument. The common practice is to independently build (a.k.a., clean build) a software for a subset of configurations. While incremental build has been considered for software evolution and relatively small modifications of the source code, it has surprisingly not been considered for software configurations. In this vision paper, we formulate the hypothesis that incremental build can reduce the cost of exploring the configuration space of software systems. We detail how we apply incremental build for two real-world application scenarios and conduct a preliminary evaluation on two case studies, namely x264 and Linux Kernel. For x264, we found that one can incrementally build configurations in an order such that overall build time is reduced. Nevertheless, we could not find any optimal order with the Linux Kernel, due to a high distance between random configurations. Therefore, we show it is possible to control the process of generating configurations: we could reuse commonality and gain up to 66% of build time compared to only clean builds.","Georges Aaron Randrianaina,Randrianaina, Georges Aaron,Djamel Eddine Khelladi,Khelladi, Djamel, ,Olivier Zendra,Zendra, Olivier,Mathieu Acher,Acher, Mathieu",,2022.0
10.1109/icse-nier55298.2022.9793538,,,Towards Incremental Build of Software Configurations,"Building software is a crucial task to compile, test, and deploy software systems while continuously ensuring quality. As software is more and more configurable, building multiple configurations is a pressing need, yet, costly and challenging to instrument. The common practice is to independently build (a.k.a., clean build) a software for a subset of configurations. While incremental build has been considered for software evolution and relatively small modifications of the source code, it has surprisingly not been considered for software configurations. In this vision paper, we formulate the hypothesis that incremental build can reduce the cost of exploring the configuration space of software systems. We detail how we apply incremental build for two real-world application scenarios and conduct a preliminary evaluation on two case studies, namely x264 and Linux Kernel. For x264, we found that one can incrementally build configurations in an order such that overall build time is reduced. Nevertheless, we could not find any optimal order with the Linux Kernel, due to a high distance between random configurations. Therefore, we show it is possible to control the process of generating configurations: we could reuse commonality and gain up to 66&#x0025; of build time compared to only clean builds.CCS CONCEPTS &#x2022; Software and its engineering $\\rightarrow$ Software configuration management and version control systems.","Georges Aaron Randrianaina,Georges Aaron Randrianaina,Djamel Eddine Khelladi,Djamel Eddine Khelladi,Olivier Zendra,Olivier Zendra,Mathieu Acher,Mathieu Acher",,2022.0
10.1109/cps-iotbench56135.2022.00007,,,Regression Model Trees: Compact Energy Models for Complex IoT Devices,"The energy and timing behaviour of embedded components such as radio chips or sensors plays an important role when developing energy-efficient cyber-physical systems and IoT devices. However, datasheet values generally have low accuracy and may be incomplete, and performing new energy measurements after each code or hardware configuration change is time-consuming. While energy models &#x2013; automatically generated from benchmarks exercising all relevant device configurations &#x2013; offer a solution, they should have both low prediction error and low complexity in order to be useful to humans as well as energy simulations. With today&#x2019;s increasingly complex devices and drivers, generating compact and accurate energy models is becoming harder due to non-linear effects and interdependencies between configuration parameters. To address this issue, we present Regression Model Trees. By combining software product line engineering and energy modeling methodologies, these are capable of automatically learning complex energy models from benchmark data. Using energy and timing benchmarks on two embedded radio chips and an air quality sensor, we show that Regression Model Trees are both more accurate than conventional energy models and less complex than state-of-the-art approaches from the product line engineering community. Thus, they are easier to understand and use for humans and algorithms alike. We observe two-to 100-fold complexity reduction, and a maximum energy model error of 6 % with cross-validation.","Daniel Friesel,Daniel Friesel,Olaf Spinczyk,Olaf Spinczyk",,2022.0
10.1145/3510003.3510190,,,On the benefits and limits of incremental build of software configurations,"Software projects use build systems to automate the compilation, testing, and continuous deployment of their software products. As software becomes increasingly configurable, the build of multiple configurations is a pressing need, but expensive and challenging to implement. The current state of practice is to build independently (a.k.a., clean build) a software for a subset of configurations. While incremental build has been studied for software evolution and relatively small changes of the source code, it has surprisingly not been considered for software configurations. In this exploratory study, we examine the benefits and limits of building software configurations incrementally, rather than always building them cleanly. By using five real-life configurable systems as subjects, we explore whether incremental build works, outperforms a sequence of clean builds, is correct w.r.t. clean build, and can be used to find an optimal ordering for building configurations. Our results show that incremental build is feasible in 100% of the times in four subjects and in 78% of the times in one subject. In average, 88.5% of the configurations could be built faster with incremental build while also finding several alternatives faster incremental builds. However, only 60% of faster incremental builds are correct. Still, when considering those correct incremental builds with clean builds, we could always find an optimal order that is faster than just a collection of clean builds with a gain up to 11.76%.","Georges Aaron Randrianaina,Georges Aaron Randrianaina,Xhevahire Tërnava,Xhevahire Tërnava,Djamel Eddine Khelladi,Djamel Eddine Khelladi,Mathieu Acher,Mathieu Acher",,
10.1007/978-3-031-08129-3_3,,,Scratching the Surface of ./configure: Learning the Effects of Compile-Time Options on Binary Size and Gadgets,"AbstractNumerous software systems are configurable through compile-time options and the widely used ./configure. However, the combined effects of these options on binary’s non-functional properties (size and attack surface) are often not documented, and or not well understood, even by experts. Our goal is to provide automated support for exploring and comprehending the configuration space (a.k.a., surface) of compile-time options using statistical learning techniques. In this paper, we perform an empirical study on four C-based configurable systems. We measure the variation of binary size and attack surface (by quantifying the number of code reuse gadgets) in over 400 compile-time configurations of a subject system. We then apply statistical learning techniques on top of our build infrastructure to identify how compile-time options relate to non-functional properties. Our results show that, by changing the default configuration, the system’s binary size and gadgets vary greatly (roughly \(-79\%\) to \(244\%\) and \(-77\%\) to \(30\%\), respectively). Then, we found out that identifying the most influential options can be accurately learned with a small training set, while their relative importance varies across size and attack surface for the same system. Practitioners can use our approach and artifacts to explore the effects of compile-time options in order to take informed decisions when configuring a system with ./configure. KeywordsConfigurable systemsCompile-time variabilityBinary sizeGadgetsSystem securityNon-functional propertiesStatistical learning","Xhevahire Tërnava,Xhevahire Tërnava,Mathieu Acher,Mathieu Acher,Luc Lesoil,Luc Lesoil,Arnaud Blouin,Arnaud Blouin,Jean-Marc Jézéquel,Jean-Marc Jézéquel",Lecture Notes in Computer Science,2022.0
10.1145/3503229.3547057,,,Defining categorical reasoning of numerical feature models with feature-wise and variant-wise quality attributes,,"Daniel-Jesus Munoz,Daniel-Jesús Munoz,Mónica Pinto,Mónica Pinto,Dilian Gurov,Dilian Gurov,Lidia Fuentes,Lidia Fuentes",,2022.0
10.1145/3503229.3547026,,,kconfig-webconf,"Despite decades of research and clear advantages, performance-aware configuration of real-world software product lines is still an exception rather than the norm. One reason for this may be tooling: configuration software with support for non-functional property models is generally not compatible with the configuration and build process of existing product lines. Specifically, the Kconfig language is popular in open source software projects, but neither language nor configuration frontends support performance models. To address this, we present kconfig-webconf: a performance-aware, Kconfig-compatible software product line configuration frontend. It is part of a toolchain that can automatically generate performance models with a minimal amount of changes to a software product line's build process. With such a performance model, kconfig-webconf can serve as a performance-aware drop-in replacement for existing Kconfig frontends. We evaluate its usage in five examples, including the busybox multi-call binary and the resKIL agricultural AI product line.","Daniel Friesel,Daniel Friesel,Kathrin Elmenhorst,Kathrin Elmenhorst,Lennart Kaiser,Lennart Kaiser,Michael Müller,Michael Müller,Olaf Spinczyk,Olaf Spinczyk",,2022.0
10.1145/3546932.3546991,,,Adaptive behavioral model learning for software product lines,"Behavioral models enable the analysis of the functionality of software product lines (SPL), e.g., model checking and model-based testing. Model learning aims to construct behavioral models. Due to the commonalities among the products of an SPL, it is possible to reuse the previously-learned models during the model learning process. In this paper, an adaptive approach, called PL*, for learning the product models of an SPL is presented based on the well-known L* algorithm. In this method, after learning each product, the sequences in the final observation table are stored in a repository which is used to initialize the observation table of the remaining products. The proposed algorithm is evaluated on two open-source SPLs and the learning cost is measured in terms of the number of rounds, resets, and input symbols. The results show that for complex SPLs, the total learning cost of PL* is significantly lower than that of the non-adaptive method in terms of all three metrics. Furthermore, it is observed that the order of learning products affects the efficiency of PL*. We introduce a heuristic to determine an ordering which reduces the total cost of adaptive learning.","Shaghayegh Tavassoli,Shaghayegh Tavassoli,Carlos Diego N. Damasceno,Carlos Diego Nascimento Damasceno,Ramtin Khosravi,Ramtin Khosravi,Mohammad Reza Mousavi,Mohammad Reza Mousavi",,2022.0
10.1016/j.jss.2023.111883,,,Learning input-aware performance models of configurable systems: An empirical evaluation,,"Luc Lesoil,Helge Spieker,Arnaud Gotlieb,Mathieu Acher,Paul Temple,Arnaud Blouin,Jean-Marc Jézéquel",,2024.0
10.1109/ase56229.2023.00091,,,CoMSA: A Modeling-Driven Sampling Approach for Configuration Performance Testing,"Highly configurable systems enable customers to flexibly configure the systems in diverse deployment environments. The flexibility of configurations also poses challenges for performance testing. On one hand, there exist a massive number of possible configurations; while on the other hand, the time and resources are limited for performance testing, which is already a costly process during software development. Modeling the performance of configurations is one of the solutions to reduce the cost of configuration performance testing. Although prior research proposes various modeling and sampling techniques to build configuration performance models, the sampling approaches used in the model typically do not consider the accuracy of the performance models, leading to potential sub-optimal performance modeling results in practice. In this paper, we present a modeling-driven sampling approach (CoMSA) to improve the performance modeling of highly configurable systems. The intuition of CoMSA is to select samples based on their uncertainties to the performance models. In other words, the configurations that have the more uncertain performance prediction results by the performance models are more likely to be selected as further training samples to improve the model. CoMSA is designed by considering both scenarios where 1) the software projects do not have historical performance testing results (cold start) and 2) there exist historical performance testing results (warm start). We evaluate the performance of our approach in four subjects, namely LRZIP, LLVM, x264, and SQLite. Through the evaluation result, we can conclude that our sampling approaches could highly enhance the accuracy of the prediction models and the efficiency of configuration performance testing compared to other baseline sampling approaches.","Yi Xia,Zishuo Ding,Weiyi Shang",,2023.0
10.1007/978-3-031-34560-9_4,,,Configuration Optimization with Limited Functional Impact,"Dealing with a large configuration space is a complex task for developers, especially when configurations must comply with both functional constraints and non-functional goals. In this paper, we introduce an approach to optimize any set of performance indicators for an existing configuration, while meeting functional requirements. The efficiency of this approach is assessed by exhaustively optimizing a configurable system, and by analyzing how the algorithm navigates through the configuration space. This approach proves especially efficient at optimizing configurations through a minimal number of changes, thus limiting the impact on their functional behavior.","Edouard Guégain,Amir Taherkordi,Clément Quinton",,2023.0
10.1145/3611663,,,Finding Near-Optimal Configurations in Colossal Spaces with Statistical Guarantees,"A Software Product Line SPL is a family of similar programs. Each program is defined by a unique set of features, called a configuration , that satisfies all feature constraints. “What configuration achieves the best performance for a given workload?” is the SPL Optimization SPLO challenge. SPLO is daunting: just 80 unconstrained features yields 10 24 unique configurations, which equals the estimated number of stars in the universe. We explain (a) how uniform random sampling and random search algorithms solve SPLO more efficiently and accurately than current machine-learned performance models, and (b) how to compute statistical guarantees on the quality of a returned configuration, i.e., it is within x% of optimal with y% confidence.","Jeho Oh,Don Batory,Rubén Heradio",,2023.0
10.1145/3579028.3609016,,,Generative AI for Reengineering Variants into Software Product Lines,"The migration and reengineering of existing variants into a software product line (SPL) is an error-prone and time-consuming activity. Many extractive approaches have been proposed, spanning different activities from feature identification and naming to the synthesis of reusable artefacts. In this paper, we explore how large language model (LLM)-based assistants can support domain analysts and developers. We revisit four illustrative cases of the literature where the challenge is to migrate variants written in different formalism (UML class diagrams, Java, GraphML, statecharts). We systematically report on our experience with ChatGPT-4, describing our strategy to prompt LLMs and documenting positive aspects but also failures. We compare the use of LLMs with state-of-the-art approach, BUT4Reuse. While LLMs offer potential in assisting domain analysts and developers in transitioning software variants into SPLs, their intrinsic stochastic nature and restricted ability to manage large variants or complex structures necessitate a semiautomatic approach, complete with careful review, to counteract inaccuracies.","Mathieu Acher,Jabier Martínez",,2023.0
10.1145/3579027.3608972,,,On Programming Variability with Large Language Model-based Assistant,"Programming variability is central to the design and implementation of software systems that can adapt to a variety of contexts and requirements, providing increased flexibility and customization. Managing the complexity that arises from having multiple features, variations, and possible configurations is known to be highly challenging for software developers. In this paper, we explore how large language model (LLM)-based assistants can support the programming of variability.We report on new approaches made possible with LLM-based assistants, like: features and variations can be implemented as prompts; augmentation of variability out of LLM-based domain knowledge; seamless implementation of variability in different kinds of artefacts, programming languages, and frameworks, at different binding times (compile-time or run-time). We are sharing our data (prompts, sessions, generated code, etc.) to support the assessment of the effectiveness and robustness of LLMs for variability-related tasks.","Mathieu Acher,José Galindo,Jean-Marc Jézéquel",,2023.0
10.1145/3579027.3608989,,,True Variability Shining Through Taxonomy Mining,"Software variants of a Software Product Line (SPL) consist of a set of artifacts specified by features. Variability models document the valid relationships between features and their mapping to artifacts. However, research has shown inconsistencies between the variability of variants in features and artifacts, with negative effects on system safety and development effort. To analyze this mismatch in variability, the causal relationships between features, artifacts, and variants must be uncovered, which has only been addressed to a limited extent. In this paper, we propose taxonomy graphs as novel variability models that reflect the composition of variants from artifacts and features, making mismatches in variability explicit. Our evaluation with two SPL case studies demonstrates the usefulness of our variability model and shows that mismatches in variability can vary significantly in detail and severity.","Christoph König,Kamil Rosiak,Loek Cleophas,Ina Schaefer",,2023.0
10.1145/3624007.3624058,,,Unleashing the Power of Implicit Feedback in Software Product Lines: Benefits Ahead,"Software Product Lines (SPLs) facilitate the development of a complete range of software products through systematic reuse. Reuse involves not only code but also the transfer of knowledge gained from one product to others within the SPL. This transfer includes bug fixing, which, when encountered in one product, affects the entire SPL portfolio. Similarly, feedback obtained from the usage of a single product can inform beyond that product to impact the entire SPL portfolio. Specifically, implicit feedback refers to the automated collection of data on software usage or execution, which allows for the inference of customer preferences and trends. While implicit feedback is commonly used in single-product development, its application in SPLs has not received the same level of attention. This paper promotes the investigation of implicit feedback in SPLs by identifying a set of SPL activities that can benefit the most from it. We validate this usefulness with practitioners using a questionnaire-based approach (n=8). The results provide positive insights into the advantages and practical implications of adopting implicit feedback at the SPL level.","Raul Medeiros,Óscar Díaz,David Benavides",,2023.0
10.1145/3551349.3559499,,,"Automated Identification of Security-Relevant Configuration Settings
  Using NLP","To secure computer infrastructure, we need to configure all security-relevant settings. We need security experts to identify security-relevant settings, but this process is time-consuming and expensive. Our proposed solution uses state-of-the-art natural language processing to classify settings as security-relevant based on their description. Our evaluation shows that our trained classifiers do not perform well enough to replace the human security experts but can help them classify the settings. By publishing our labeled data sets and the code of our trained model, we want to help security experts analyze configuration settings and enable further research in this area.","Stöckle, Patrick,Patrick Stöckle,Wasserer, Theresa,Theresa Wasserer,Grobauer, Bernd,Bernd Grobauer,Pretschner, Alexander,Alexander Pretschner",,2022.0
10.1016/j.jss.2022.111539,,,Automating Feature Model maintainability evaluation using machine learning techniques,,"Públio Silva,Públio Silva,Carla Ilane Moreira Bezerra,Carla I. M. Bezerra,Ivan do Carmo Machado,Ivan Machado",Journal of Systems and Software,2022.0
10.1145/3522664.3528602,,,Black-box models for non-functional properties of AI software systems,"Non-functional properties (NFPs) such as latency, memory requirements, or hardware cost are an important characteristic of AI software systems, especially in the domain of resource-constrained embedded devices. Embedded AI products require sufficient resources for satisfactory latency and accuracy, but should also be cost-efficient and therefore not use more powerful hardware than strictly necessary. Traditionally, modeling and optimization efforts focus on the AI architecture, utilizing methods such as neural architecture search (NAS). However, before developers can start optimizing, they need to know which architectures are suitable candidates for their use case. To this end, architectures must be viewed in context: model post-processing (e.g. quantization), hardware platform, and run-time configuration such as batching all have significant effects on NFPs and therefore on AI architecture performance. Moreover, scalar parameters such as batch size cannot be benchmarked exhaustively. We argue that it is worthwhile to address this issue by means of black-box models before deciding on AI architectures for optimization and hardware/software platforms for inference. To support our claim, we present an AI product line with variable hardware and software components, perform benchmarks, and present notable results. Additionally, we evaluate both compactness and generalization capabilities of regression tree-based modeling approaches from the machine learning and product line engineering communities. We find that linear model trees perform best: they can capture NFPs of known AI configurations with a mean error of up to 13 %, and can predict unseen configurations with a mean error of 10 to 26 %. We find linear model trees to be more compact and interpretable than other tree-based approaches.","Daniel Friesel,Olaf Spinczyk",,2022.0
10.1007/978-3-031-15629-8_8,,,Family-Based Fingerprint Analysis: A Position Paper,"AbstractThousands of vulnerabilities are reported on a monthly basis to security repositories, such as the National Vulnerability Database. Among these vulnerabilities, software misconfiguration is one of the top 10 security risks for web applications. With this large influx of vulnerability reports, software fingerprinting has become a highly desired capability to discover distinctive and efficient signatures and recognize reportedly vulnerable software implementations. Due to the exponential worst-case complexity of fingerprint matching, designing more efficient methods for fingerprinting becomes highly desirable, especially for variability-intensive systems where optional features add another exponential factor to its analysis. This position paper presents our vision of a framework that lifts model learning and family-based analysis principles to software fingerprinting. In this framework, we propose unifying databases of signatures into a featured finite state machine and using presence conditions to specify whether and in which circumstances a given input-output trace is observed. We believe feature-based signatures can aid performance improvements by reducing the size of fingerprints under analysis.KeywordsModel LearningVariability ManagementFamily-Based AnalysisSoftware Fingerprinting","Carlos Diego Nascimento Damasceno,Carlos Diego Nascimento Damasceno,Daniel Strüber,Daniel Strüber",Lecture Notes in Computer Science,2022.0
10.1145/3572905,,,Machine Learning for Software Engineering: A Tertiary Study,"Machine learning (ML) techniques increase the effectiveness of software engineering (SE) lifecycle activities. We systematically collected, quality-assessed, summarized, and categorized 83 reviews in ML for SE published between 2009–2022, covering 6 117 primary studies. The SE areas most tackled with ML are software quality and testing, while human-centered areas appear more challenging for ML. We propose a number of ML for SE research challenges and actions including: conducting further empirical validation and industrial studies on ML; reconsidering deficient SE methods; documenting and automating data collection and pipeline processes; reexamining how industrial practitioners distribute their proprietary data; and implementing incremental ML approaches.","Zoe Kotti,Rafaila Galanopoulou,Diomidis Spinellis",ACM Computing Surveys,2022.0
